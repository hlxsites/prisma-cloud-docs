== Features Introduced in May 2025

Learn what's new on Prisma® Cloud in May 2025.

//* <<new-features>>
* <<enhancements>>
//* <<changes-in-existing-behavior>>
* <<api-ingestions>>
* <<new-policies>>
* <<policy-updates>>
//* <<iam-policy-updates>>
* <<new-compliance-benchmarks-and-updates>>
//* <<rest-api-updates>>
//* <<deprecation-notices>>


//[#new-features]
//=== New Features
//[cols="30%a,70%a"]
//|===
//|*Feature*
//|*Description*
//|===


[#enhancements]
=== Enhancements
[cols="50%a,50%a"]
|===
|*Feature*
|*Description*

|*Ingestion of Azure VNet Flowlogs*

|Prisma Cloud now supports the ingestion of VNet flowlogs along with the existing ingestion of NSG logs, for Microsoft Azure account onboarding. VNet flowlogs will also be added as a data source to existing Azure policies. There will be no impact to existing tenants and no additional action is needed.

|*Ingestion of AWS ca-west-1*

|Prisma Cloud AWS resource discovery is now extended to resources on AWS ca-west-1 (Canada/Calgary). With this added ingestion support, assets in this region are discoerable on the *Asset Inventory* page. No further action is needed.   

|===

//[#changes-in-existing-behavior]
//=== Changes in Existing Behavior
//[cols="30%a,70%a"]
//|===
//|*Feature*
//|*Description*

//|===



[#api-ingestions]
=== API Ingestions

[cols="50%a,50%a"]
|===
|*Service*
|*API Details*

|*AWS HealthLake*
//RLP-155698

|*aws-healthlake-datastore*

Additional permissions required:

* `healthlake:ListFHIRDatastores`
* `healthlake:DescribeFHIRDatastore`

The Security audit role includes `healthlake:ListFHIRDatastores` permission but does not include `healthlake:DescribeFHIRDatastore` permission.

|*Azure API Management Services*
//RLP-155662

|*azure-api-management-service-named-value*

Additional permissions required:

* `Microsoft.ApiManagement/service/apis/read`
* `Microsoft.ApiManagement/service/namedValues/read`

The Reader role includes the permissions.

|*Azure Healthcare APIs*
//RLP-155671

|*azure-healthcare-apis-workspace-fhir-service*

Additional permission required:

* `Microsoft.HealthcareApis/workspaces/read Microsoft.HealthcareApis/workspaces/fhirservices/read`

The Reader role includes the permission.

|*Azure Healthcare APIs*
//RLP-155670

|*azure-healthcare-apis-workspace-dicom-service*

Additional permissions required:

* `Microsoft.HealthcareApis/workspaces/read`
* `Microsoft.HealthcareApis/workspaces/dicomservices/read`

The Reader role includes the permissions.


|*Azure IoT Central*
//RLP-155708

|*azure-iot-central-private-endpoint-connections*

Additional permissions required:

* `Microsoft.IoTCentral/IoTApps/read`
* `Microsoft.IoTCentral/IoTApps/privateEndpointConnections/read`

The Reader role includes the permissions.

|*Azure IoT Hub*
//RLP-155705

|*azure-iot-hub-device-provisioning-service*

Additional permission required:

* `Microsoft.Devices/provisioningServices/Read`

The Reader role includes the permission.

|*Azure IoT Hub*
//RLP-155700

|*azure-devices-iot-hub-private-endpoint-connections*

Additional permissions required:

* `Microsoft.Devices/iotHubs/Read`
* `Microsoft.Devices/iotHubs/PrivateEndpointConnections/Read`

The Reader role includes the permissions.


|*Azure Kusto*
//RLP-155669

|*azure-kusto-database-principal-assignment*

Additional permissions required:

* `Microsoft.Kusto/Clusters/read `
* `Microsoft.Kusto/Clusters/Databases/read`
* `Microsoft.Kusto/Clusters/Databases/PrincipalAssignments/read`

The Reader role includes the permissions.

|*Azure Kusto*
//RLP-155668

|*azure-kusto-cluster-private-link-resource*

Additional permissions required:

* `Microsoft.Kusto/Clusters/read`
* `Microsoft.Kusto/Clusters/PrivateLinkResources/read`

The Reader role includes the permissions.

|*Azure Kusto*
//RLP-155666

|*azure-kusto-cluster-principal-assignment*

Additional permissions required:

* `Microsoft.Kusto/Clusters/read`
* `Microsoft.Kusto/Clusters/PrincipalAssignments/read`

The Reader role includes the permissions.

|*Azure Kusto*
//RLP-155664

|*azure-kusto-cluster-managed-private-endpoint*

Additional permissions required:

* `Microsoft.Kusto/Clusters/read`
* `Microsoft.Kusto/Clusters/ManagedPrivateEndpoints/read`

The Reader role includes the permissions.

|*Azure Recovery Services*
//RLP-155923
|*azure-recovery-service-private-link*

Additional permissions required:

* `Microsoft.RecoveryServices/Vaults/read`
* `Microsoft.RecoveryServices/Vaults/privateLinkResources/read`

The Reader role includes the permissions.

|*Azure Storage*
//RLP-155925
|*azure-storage-account-blob-service-property*

Additional permissions required:

* `Microsoft.Storage/storageAccounts/read`
* `Microsoft.Storage/storageAccounts/blobServices/read`

The Reader role includes the permissions.

|tt:[Update] *Azure Synapse Analytics*
//RLP-155930
|*azure-synapse-workspace*

Additional permissions required:

* `Microsoft.Synapse/workspaces/dedicatedSQLminimalTlsSettings/read `

The additional permission above is now required.

|tt:[Update] *Azure Synapse Analytics*
//RLP-155926
|*azure-synapse-workspace-sql-pools*

Additional permissions required:

* `Microsoft.Synapse/workspaces/sqlPools/transparentDataEncryption/read`

The additional permission above is now required.

|*Google Resource Manager*
//RLP-131423
|*gcloud-project-tag-key*

Additional permissions required:

* `resourcemanager.tagKeys.list`
* `resourcemanager.tagKeys.getIamPolicy`

The Viewer role includes the permissions.

|*Google Resource Manager*
//RLP-131424
|*gcloud-organization-tag-key*

Additional permissions required:

* `resourcemanager.tagKeys.list`
* `resourcemanager.tagKeys.getIamPolicy`

The Viewer role includes the permissions.

|*Google Cloud TPU*
//RLP-155869
|*gcloud-tpu-node*

Additional permission required:

* `tpu.nodes.list`

The Viewer role includes the permission.


|*OCI IAM*
//RLP-155562
|*oci-iam-password-policy*

Additional permissions required:

* `COMPARTMENT_INSPECT`
* `DOMAIN_INSPECT`
* `PASSWORD_POLICY_INSPECT`

The Reader role includes the permissions.

|===


[#new-policies]
=== New Policies

[cols="40%a,60%a"]
|===
|*Policies*
|*Description*

|*AWS Lightsail Instance allows ingress from the internet*
//RLP-155270

|*Policy Description—* Unrestricted internet ingress to AWS Lightsail instances exposes them to unauthorized access. This misconfiguration leaves instances vulnerable to various attacks.

AWS Lightsail instances use a built-in firewall to control inbound traffic. By default, or through misconfiguration, all ports might be open to the internet. This allows attackers to easily scan for open ports and exploit known vulnerabilities, leading to instance compromise and data breaches. Attackers can launch brute-force attacks against common services like SSH, potentially gaining full control.

The impact of this misconfiguration includes data exfiltration, unauthorized modification of instance resources, and potential use as a stepping stone for further attacks within the cloud environment. Limiting access to only trusted IP addresses is crucial for minimizing the attack surface and preventing unauthorized access.

Implement a least privilege approach. Configure the Lightsail instance's firewall to allow only necessary ports and specific trusted IP addresses. Regularly review and update firewall rules to remove any unnecessary access and mitigate the risk of unauthorized connections. Monitor logs for suspicious activity.

*Policy Severity—* Low

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'aws' AND api.name = 'aws-lightsail-instance' AND json.rule = state.name contains "running" and networking.ports[?any( accessDirection equals inbound and (cidrs contains "0.0.0.0/0" or ipv6Cidrs contains "::/0"))] exists`
----


|*AWS Lightsail Instance not configured with Instance Metadata Service v2 (IMDSv2)*
//RLP-155269

|*Policy Description—* AWS Lightsail instances lacking Instance Metadata Service version 2 (IMDSv2) configuration pose a significant security risk. Instances without IMDSv2 are vulnerable to unauthorized access to sensitive metadata, potentially leading to data breaches or server compromise.

The Instance Metadata Service provides metadata about the instance, including details like instance ID, security credentials, and private IP address. Without IMDSv2's session authentication, attackers could exploit misconfigurations or vulnerabilities in other services (like misconfigured firewalls or reverse proxies) to access this sensitive information. This access can facilitate lateral movement within an environment or enable unauthorized actions on the instance.

Failure to enforce IMDSv2 exposes the instance to various attack vectors, resulting in data exfiltration, privilege escalation, and complete system compromise. Employing IMDSv2 ensures requests are authenticated, thereby mitigating these risks and protecting sensitive data.

To remediate this misconfiguration, explicitly enable IMDSv2 for all AWS Lightsail instances. This can typically be accomplished through the AWS console or CLI, configuring the instance settings. Regularly audit your instances to ensure consistent IMDSv2 implementation across your environment.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'aws' AND api.name = 'aws-lightsail-instance' AND json.rule = metadataOptions exists and metadataOptions.httpTokens equal ignore case optional`
----


|*GCP AlloyDB Cluster instance allows direct unencrypted connection*
//RLP-155478

|*Policy Description—* GCP AlloyDB Cluster instances permitting unencrypted connections pose a significant security risk, exposing sensitive data in transit to eavesdropping and unauthorized access.

The AlloyDB service allows both encrypted and unencrypted connections by default if SSL is not explicitly enabled. Disabling SSL introduces a major security risk, as all communication with the database instance occurs in plain text. Attackers can intercept this data easily, potentially leading to data breaches and unauthorized database modifications.

A misconfiguration allowing unencrypted connections exposes sensitive data, impacting confidentiality and integrity. Enabling SSL is crucial to protect data in transit, ensuring only authorized users with properly authenticated connections can access the database. This practice aligns with industry best practices for securing database communication.

To mitigate this, enforce SSL encryption on all AlloyDB Cluster instances. Configure the instance to only accept encrypted connections. Regularly audit configurations to ensure SSL remains enabled and verify all connections utilize SSL encryption.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' and api.name = 'gcloud-alloydb-cluster-instance' AND json.rule = state equal ignore case ready and clientConnectionConfig.sslConfig.sslMode equal ignore case ALLOW_UNENCRYPTED_AND_ENCRYPTED`
----


|*GCP AlloyDB instance with IAM authentication disabled*
//RLP-155477

|*Policy Description—* GCP AlloyDB instances lacking IAM authentication are susceptible to unauthorized access. Disabling IAM authentication relies solely on database passwords for access, increasing the risk of breaches via password compromise or leaks.

AlloyDB's IAM authentication integrates with Google Cloud's Identity and Access Management system, enabling granular control over database access. Without IAM, security relies on password management alone, which is vulnerable to brute-force attacks, phishing, or weak password policies. This misconfiguration exposes sensitive data within the database to unauthorized individuals or malicious actors.

The impact of this misconfiguration includes data breaches, unauthorized database modifications, and potential service disruptions. Enabling IAM authentication provides a more secure authentication method by leveraging the robust security features of GCP's IAM system, minimizing the risk of unauthorized access and improving overall security posture.

To mitigate this, ensure IAM authentication is enabled on all AlloyDB instances. Regularly review and update IAM permissions to ensure only authorized users and service accounts have access. Implement strong password policies and multi-factor authentication (MFA) for all database users, even when IAM authentication is enabled, as an additional layer of security.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' and api.name = 'gcloud-alloydb-cluster-instance' AND json.rule = (['databaseFlags'].['alloydb.iam_authentication'] does not exist or ['databaseFlags'].['alloydb.iam_authentication'] does not equal ignore case on)`
----


|*GCP AlloyDB Instance with insecure password policy*
//RLP-155476

|*Policy Description—* Insecure password policies on GCP AlloyDB instances allow unauthorized access. Weak or easily guessable passwords increase the risk of database compromise.

GCP AlloyDB instances utilize password-based authentication. A weak password policy increases the likelihood of brute-force or credential stuffing attacks leading to data breaches and unauthorized modifications. Failure to enforce strong passwords exposes the database to significant security risks.

Compromised AlloyDB instances can result in data exfiltration, service disruption, and financial losses. Enforcing a robust password policy significantly reduces the risk of unauthorized access by requiring complex and regularly updated passwords.

Implement a strong password policy for all AlloyDB instances. Ensure 'password.enforce_complexity', 'password.enforce_expiration', and 'password.enforce_password_does_not_contain_username' are set to 'on'. 'password.expiration_in_days' should be less than 90, 'password.min_pass_length' greater than or equal to 10, and 'password.min_uppercase_letters' and 'password.min_numerical_chars' should be at least 1. Regularly review and update password policies.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-alloydb-cluster-instance' AND json.rule = (['databaseFlags'].['password.enforce_complexity'] does not exist or ['databaseFlags'].['password.enforce_complexity'] does not equal ignore case on) or (['databaseFlags'].['password.enforce_expiration'] does not exist or ['databaseFlags'].['password.enforce_expiration'] does not equal ignore case on) or (['databaseFlags'].['password.expiration_in_days'] does not exist or ['databaseFlags'].['password.expiration_in_days'] > 90) or (['databaseFlags'].['password.min_uppercase_letters'] does not exist or ['databaseFlags'].['password.min_uppercase_letters'] < 1) or (['databaseFlags'].['password.min_numerical_chars'] does not exist or ['databaseFlags'].['password.min_numerical_chars'] < 1) or (['databaseFlags'].['password.min_pass_length'] does not exist or ['databaseFlags'].['password.min_pass_length'] < 10) or (['databaseFlags'].['password.enforce_password_does_not_contain_username'] does not exist or ['databaseFlags'].['password.enforce_password_does_not_contain_username'] does not equal ignore case on)`
----


|*GCP AlloyDB Cluster's Continuous Backup not encrypted with CMEK*
//RLP-155475

|*Policy Description—* GCP AlloyDB clusters lacking CMEK encryption for continuous backups expose sensitive data to unauthorized access.

AlloyDB's continuous backup feature, enabled by default, creates cluster backups. Without CMEK encryption, these backups are protected by Google-managed keys, reducing organizational control over sensitive data. Attackers gaining access to Google's infrastructure could potentially decrypt and exfiltrate this data.

A data breach resulting from this misconfiguration could lead to significant financial losses, regulatory penalties, and reputational damage. Encrypting backups with CMEK ensures only authorized users with access to the customer-managed encryption keys can decrypt and access the data, aligning with data security best practices and minimizing the impact of potential breaches.

To mitigate this risk, enable CMEK encryption for all AlloyDB cluster continuous backups. Regularly review and audit CMEK key management practices to ensure ongoing protection. Implement strong access controls to restrict access to the CMEK keys.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-alloydb-cluster' AND json.rule = continuousBackupInfo.encryptionInfo.encryptionType equal ignore case GOOGLE_DEFAULT_ENCRYPTION`
----


|*GCP Dataproc Serverless Batch is using default network*
//RLP-155462

|*Policy Description—* GCP Dataproc Serverless Batch instances are deployed on the default network, exposing them to unnecessary risks. This misconfiguration increases the attack surface and compromises security posture.

The default network lacks granular control over network traffic and resource isolation. It offers broad access between resources, allowing unauthorized communication between Dataproc instances and other GCP services or external entities. This can lead to data breaches, unauthorized access to sensitive data, and lateral movement within the GCP environment.

This misconfiguration significantly impacts the organization's security and compliance posture. A compromised Dataproc Serverless Batch instance could lead to data loss, service disruption, and reputational damage. Implementing a custom Virtual Private Cloud (VPC) network with appropriate firewall rules and subnets is crucial for enhancing security and mitigating risks.

To remediate this, use a custom VPC network for Dataproc Serverless Batch. Configure appropriate firewall rules to restrict inbound and outbound traffic to only necessary services and IP addresses. Segment your network using subnets to isolate resources and enhance security. Utilize private Google Access for secure communication with Google services.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-dataproc-serverless-batch' AND json.rule = state is member of ("PENDING", "RUNNING") and ( environmentConfig.executionConfig.networkUri ends with "default" or environmentConfig.executionConfig.subnetworkUri ends with "default")`
----


|*GCP Dataproc Serverless Session template is using default network*
//RLP-155461

|*Policy Description—* GDataproc Serverless session templates utilizing the default network in GCP pose a significant security risk. The default network lacks the necessary security controls and isolation for production workloads, increasing the attack surface.

GCP's default network offers broad access between resources, enabling unauthorized communication between instances. This lack of segmentation and inherent misconfiguration increases the risk of data breaches and lateral movement if an attacker compromises a single instance. Without customized firewall rules and network policies, the default network's open nature is easily exploited.

The impact of this misconfiguration is substantial, potentially leading to unauthorized data access, system compromise, and significant business disruption. Implementing a custom Virtual Private Cloud (VPC) network with tailored firewall rules and appropriate subnet segmentation is crucial for mitigating these risks. This provides better control over network traffic, access, and resource isolation.

To remediate this issue, use a custom VPC network and migrate Dataproc Serverless session templates to this new network. Implement appropriate firewall rules to restrict access to only authorized IP addresses and services. Segment the network using subnets to further isolate resources and enforce the principle of least privilege. Regularly review and update network configurations to maintain security posture.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-dataproc-serverless-session-template' AND json.rule = environmentConfig.executionConfig.networkUri ends with "default" or environmentConfig.executionConfig.subnetworkUri ends with "default"`
----

|*GCP Dataproc Serverless Session is using default network*
//RLP-155460

|*Policy Description—* Dataproc Serverless sessions using the default network in GCP pose a significant security risk. This misconfiguration exposes resources to unintended network access and lacks essential security controls.

The default network in GCP provides broad, unrestricted access between all instances. This lack of network segmentation allows unauthorized communication between sensitive and non-sensitive workloads. An attacker exploiting a misconfigured application within one instance could easily pivot to other instances within the default network. This lack of isolation dramatically increases the attack surface and the potential for data breaches or system compromises.

The impact of this misconfiguration includes data breaches, unauthorized access to sensitive information, and compromised application integrity. Employing a custom VPC with appropriate firewall rules and network segmentation ensures that only authorized traffic can access resources. This practice enhances security posture and reduces the likelihood of successful attacks.

To mitigate this risk, use a custom Virtual Private Cloud (VPC) network for Dataproc Serverless. Configure appropriate firewall rules to restrict inbound and outbound network traffic to only authorized sources and destinations. Implement network segmentation by creating subnets for different workloads, further limiting the impact of potential breaches.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-dataproc-serverless-session' AND json.rule = state is member of ("CREATING", "ACTIVE") and ( environmentConfig.executionConfig.networkUri ends with "default" or environmentConfig.executionConfig.subnetworkUri ends with "default")`
----


|*GCP Dataproc Cluster on GKE is using default network*
//RLP-155459

|*Policy Description—* Dataproc clusters on Google Kubernetes Engine (GKE) using the default network in GCP pose a significant security risk. This misconfiguration allows broad, unrestricted communication between all instances within the default network, bypassing necessary security controls.

The default network lacks essential security features like segmentation and fine-grained control over network traffic. It offers no inherent isolation between different workloads, increasing the risk of lateral movement and data breaches. Attackers could exploit this lack of isolation to compromise multiple systems, potentially accessing sensitive data or disrupting operations.

The impact of this misconfiguration is far-reaching. It increases the attack surface, exposes sensitive data to unauthorized access, and hinders compliance efforts. A custom Virtual Private Cloud (VPC) provides robust security through subnets, firewall rules, and improved network segmentation, mitigating these risks. Implementing these controls enhances security posture and reduces the likelihood of successful attacks.

To remediate this, use a custom VPC network with appropriately configured subnets and firewall rules. Restrict traffic flow between resources based on least privilege principles. Ensure proper segmentation of workloads and implement robust access controls to isolate sensitive data. Regularly review and update network configurations to maintain security.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where api.name = 'gcloud-dataproc-clusters-list' AND json.rule = status.state is member of ("SCHEDULED", "CREATING", "RUNNING") as X; config from cloud.resource where api.name = 'gcloud-container-describe-clusters' AND json.rule = status equals RUNNING and ['network'] ends with "default" as Y; filter ' $.Y.selfLink contains $.X.virtualClusterConfig.kubernetesClusterConfig.gkeClusterConfig.gkeClusterTarget '; show X;`
----


|*GCP Dataproc Cluster on Compute Engine is using default network*
//RLP-155458

|*Policy Description—* GCP Dataproc clusters deployed on the default network pose significant security risks due to its inherent lack of security controls and segmentation. This misconfiguration exposes the cluster to unauthorized access and potential data breaches.

The default network in GCP offers minimal security controls, allowing broad access between resources within the network. This lack of isolation increases the attack surface, enabling lateral movement and unauthorized access to sensitive data within the Dataproc cluster. Attackers could exploit this misconfiguration to gain access to the cluster and its underlying resources, potentially leading to data exfiltration or disruption of services.

The impact of this misconfiguration could range from unauthorized access to sensitive data and system compromise to complete data loss. Using a custom Virtual Private Cloud (VPC) network with appropriate firewall rules, subnets, and access controls enhances security, promotes better resource organization, and enables compliance with security regulations. Implementing robust network segmentation is crucial for isolating sensitive workloads and minimizing the impact of potential breaches.

To mitigate this risk, use a custom VPC network specifically for your Dataproc cluster. Configure appropriate firewall rules to restrict inbound and outbound traffic, allowing only necessary connections. Utilize subnets to isolate resources and apply appropriate Identity and Access Management ('IAM') policies to limit access to authorized users and services only. Regularly review and update network configurations to maintain a strong security posture.

*Policy Severity—* Medium

*Policy Type—* Config

----
`config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-dataproc-clusters-list' AND json.rule = status.state is member of ("SCHEDULED", "CREATING", "RUNNING") and ( environmentConfig.executionConfig.networkUri ends with "default" or environmentConfig.executionConfig.subnetworkUri ends with "default" or ( environmentConfig.executionConfig.networkUri does not exist and environmentConfig.executionConfig.subnetworkUri does not exist ) )`
----

|===



[#policy-updates]
=== Policy Updates

[cols="50%a,50%a"]
|===
|*Policy Updates*
|*Description*

2+|*Policy Updates—RQL*

|*Cognito service role with wide privileges does not validate authentication*
//RLP-155781

|*Changes—* Policy RQL has been updated with including the condition matching '*' in policy action

*Current RQL–* 
----
config from cloud.resource where api.name = 'aws-iam-list-roles' AND json.rule = role.assumeRolePolicyDocument.Statement[*].Action contains "sts:AssumeRoleWithWebIdentity" and role.assumeRolePolicyDocument.Statement[*].Principal.Federated contains "cognito-identity.amazonaws.com" and role.assumeRolePolicyDocument.Statement[*].Effect contains "Allow" and role.assumeRolePolicyDocument.Statement[*].Condition contains "cognito-identity.amazonaws.com:amr" and role.assumeRolePolicyDocument.Statement[*].Condition contains "unauthenticated" as X; config from cloud.resource where api.name = 'aws-iam-get-policy-version' AND json.rule = document.Statement[?any(Effect equals Allow and Action contains :* and Resource equals * )] exists as Y; filter "($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action contains :* ) or ($.X.attachedPolicies[*].policyArn intersects $.Y.policyArn)"; show X;  
----

*Updated RQL–*
----
config from cloud.resource where api.name = 'aws-iam-list-roles' AND json.rule = role.assumeRolePolicyDocument.Statement[*].Action contains "sts:AssumeRoleWithWebIdentity" and role.assumeRolePolicyDocument.Statement[*].Principal.Federated contains "cognito-identity.amazonaws.com" and role.assumeRolePolicyDocument.Statement[*].Effect contains "Allow" and role.assumeRolePolicyDocument.Statement[*].Condition contains "cognito-identity.amazonaws.com:amr" and role.assumeRolePolicyDocument.Statement[*].Condition contains "unauthenticated" as X; config from cloud.resource where api.name = 'aws-iam-get-policy-version' AND json.rule = document.Statement[?any(Effect equals Allow and (Action contains :* or Action equals *) and Resource equals * )] exists as Y; filter "($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action contains :* ) or ($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action equals * ) or ($.X.attachedPolicies[*].policyArn intersects $.Y.policyArn)"; show X;  
----

*Policy Type–* Config 

*Policy Severity–* High

*Impact–* Low. New alerts will be generated as per new RQL.


|*AWS Cognito service role with wide privileges does not validate authentication*
//RLP-155781

|*Changes—* Policy RQL has been updated with including the condition matching '*' in policy action

*Current RQL–* 
----
config from cloud.resource where api.name = 'aws-iam-list-roles' AND json.rule = role.assumeRolePolicyDocument.Statement[*].Action contains "sts:AssumeRoleWithWebIdentity" and role.assumeRolePolicyDocument.Statement[*].Principal.Federated contains "cognito-identity.amazonaws.com" and role.assumeRolePolicyDocument.Statement[*].Effect contains "Allow" and role.assumeRolePolicyDocument.Statement[*].Condition contains "cognito-identity.amazonaws.com:amr" and role.assumeRolePolicyDocument.Statement[*].Condition contains "unauthenticated" as X; config from cloud.resource where api.name = 'aws-iam-get-policy-version' AND json.rule = document.Statement[?any(Effect equals Allow and Action contains :* and Resource equals * )] exists as Y; filter "($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action contains :* ) or ($.X.attachedPolicies[*].policyArn intersects $.Y.policyArn)"; show X; 
----

*Updated RQL–*
----
config from cloud.resource where api.name = 'aws-iam-list-roles' AND json.rule = role.assumeRolePolicyDocument.Statement[*].Action contains "sts:AssumeRoleWithWebIdentity" and role.assumeRolePolicyDocument.Statement[*].Principal.Federated contains "cognito-identity.amazonaws.com" and role.assumeRolePolicyDocument.Statement[*].Effect contains "Allow" and role.assumeRolePolicyDocument.Statement[*].Condition contains "cognito-identity.amazonaws.com:amr" and role.assumeRolePolicyDocument.Statement[*].Condition contains "unauthenticated" as X; config from cloud.resource where api.name = 'aws-iam-get-policy-version' AND json.rule = document.Statement[?any(Effect equals Allow and (Action contains :* or Action equals *) and Resource equals * )] exists as Y; filter "($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action contains :* ) or ($.X.inlinePolicies[*].policyDocument.Statement[?(@.Effect=='Allow' && @.Resource=='*')].Action equals * ) or ($.X.attachedPolicies[*].policyArn intersects $.Y.policyArn)"; show X; 
----

*Policy Type–* Config 

*Policy Severity–* High

*Impact–* Low. New alerts will be generated as per new RQL.

2+|*Policy Updates—Metadata*

|*AWS S3 bucket not configured with secure data transport policy*
//RLP-155761

|*Changes—* Policy description updated to include the publicly accessible check.

*Policy Type*: Config

*Policy Severity*: Medium

*Impact*: No impact on alerts

*Updated Description*: 
----
AWS S3 buckets that are publicly accessible and lacking secure data transport are highly susceptible to data breaches during transit.
AWS S3 buckets should enforce data encryption using Secure Sockets Layer (SSL) to protect data transmitted between clients and the S3 service. Failure to enforce HTTPS allows attackers to intercept sensitive data in transit, leading to data exposure and potential breaches. Additionally, because the bucket is publicly accessible, untrusted IPs can access sensitive data without encryption.
The impact of this misconfiguration includes unauthorized access to sensitive data, data breaches, and potential regulatory fines. Enforcing HTTPS ensures all communication with publicly accessible S3 buckets is encrypted, protecting data confidentiality and integrity.
To mitigate this, configure bucket policies to explicitly deny all access except via HTTPS ('aws:SecureTransport: true') and remove public access permissions. Regularly review and update bucket policies to reflect evolving security needs and ensure that public access is minimized or removed.
----

|*AWS S3 bucket not configured with secure data transport policy*
//RLP-155761

|*Changes—* Policy description updated to include the publicly accessible check.

*Policy Type*: Config

*Policy Severity*: Medium

*Impact*: Low

*Updated Description*: 
----
AWS S3 buckets that are publicly accessible and lacking secure data transport are highly susceptible to data breaches during transit.
AWS S3 buckets should enforce data encryption using Secure Sockets Layer (SSL) to protect data transmitted between clients and the S3 service. Failure to enforce HTTPS allows attackers to intercept sensitive data in transit, leading to data exposure and potential breaches. Additionally, because the bucket is publicly accessible, untrusted IPs can access sensitive data without encryption.
The impact of this misconfiguration includes unauthorized access to sensitive data, data breaches, and potential regulatory fines. Enforcing HTTPS ensures all communication with publicly accessible S3 buckets is encrypted, protecting data confidentiality and integrity.
To mitigate this, configure bucket policies to explicitly deny all access except via HTTPS ('aws:SecureTransport: true') and remove public access permissions. Regularly review and update bucket policies to reflect evolving security needs and ensure that public access is minimized or removed.
----

|===


[#new-compliance-benchmarks-and-updates]
=== New Compliance Benchmarks and Updates

[cols="50%a,50%a"]
|===
|*Compliance Benchmark*
|*Description*

|*[Update] Australian Cyber Security Centre (ACSC) Essential Eight*
//RLP-156067

|New Policy mappings are added to Australian Cyber Security Centre (ACSC) Essential Eight compliance standard across all the levels..

*Impact*: As new mappings are introduced, compliance scoring might vary.


|*FedRAMP (High)*
//RLP-156047

|FedRAMP High compliance is the highest level of security within the Federal Risk and Authorization Management Program (FedRAMP), designed to protect highly sensitive and classified government data stored in cloud environments.

You can now access this built-in standard and related policies on the *Compliance > Standards* page. Additionally, you can generate reports to instantly view or download them, or set up scheduled reports to continuously monitor compliance.


|*[Update] CIS v3.0.0 (OCI) - Level 1 & CIS v3.0.0 (OCI) - Level 2*
//RLP-156044

|Prisma Cloud now supports the latest version of CIS Oracle Cloud Infrastructure Foundations Benchmark . This compliance standard supports two levels - Level 1 and Level 2. CIS Oracle Cloud Infrastructure Foundations Benchmark, provides prescriptive guidance for establishing a secure baseline configuration for the Oracle Cloud Infrastructure environment.

You can now access this built-in standard and related policies on the *Compliance > Standards* page. Additionally, you can generate reports to instantly view or download them, or set up scheduled reports to continuously monitor compliance.

|===


//[#rest-api-updates]
//=== REST API Updates
//[cols="37%a,63%a"]
//|===
//|*REST API*
//|*Description*
//|===

//[#deprecation-notices]
//=== Deprecation Notices
//[cols="50%a, 50%a"]
//|===
//|*Deprecated Endpoints*
//|*Replacement Endpoints*
//|===